From d0e755841f1f934bf153eb3fbb70de0e94c5a052 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Marczykowski-G=C3=B3recki?=
 <marmarek@invisiblethingslab.com>
Date: Sat, 21 Oct 2023 05:42:53 +0200
Subject: [PATCH] Revert "dm crypt: allocate compound pages if possible"

This commit causes occasional freeze of the storage I/O. Revert until
real fix is developed.

This reverts commit 5054e778fcd9cd29ddaa8109077cd235527e4f94.
---
 drivers/md/dm-crypt.c | 49 +++++++++++++------------------------------
 1 file changed, 14 insertions(+), 35 deletions(-)

diff --git a/drivers/md/dm-crypt.c b/drivers/md/dm-crypt.c
index dc0463bf3c2c..2585ce883a48 100644
--- a/drivers/md/dm-crypt.c
+++ b/drivers/md/dm-crypt.c
@@ -1669,9 +1669,6 @@ static void crypt_free_buffer_pages(struct crypt_config *cc, struct bio *clone);
  * In order to not degrade performance with excessive locking, we try
  * non-blocking allocations without a mutex first but on failure we fallback
  * to blocking allocations with a mutex.
- *
- * In order to reduce allocation overhead, we try to allocate compound pages in
- * the first pass. If they are not available, we fall back to the mempool.
  */
 static struct bio *crypt_alloc_buffer(struct dm_crypt_io *io, unsigned int size)
 {
@@ -1679,8 +1676,8 @@ static struct bio *crypt_alloc_buffer(struct dm_crypt_io *io, unsigned int size)
 	struct bio *clone;
 	unsigned int nr_iovecs = (size + PAGE_SIZE - 1) >> PAGE_SHIFT;
 	gfp_t gfp_mask = GFP_NOWAIT | __GFP_HIGHMEM;
-	unsigned int remaining_size;
-	unsigned int order = MAX_ORDER - 1;
+	unsigned int i, len, remaining_size;
+	struct page *page;
 
 retry:
 	if (unlikely(gfp_mask & __GFP_DIRECT_RECLAIM))
@@ -1693,34 +1690,19 @@ static struct bio *crypt_alloc_buffer(struct dm_crypt_io *io, unsigned int size)
 
 	remaining_size = size;
 
-	while (remaining_size) {
-		struct page *pages;
-		unsigned size_to_add;
-		unsigned remaining_order = __fls((remaining_size + PAGE_SIZE - 1) >> PAGE_SHIFT);
-		order = min(order, remaining_order);
-
-		while (order > 0) {
-			pages = alloc_pages(gfp_mask
-				| __GFP_NOMEMALLOC | __GFP_NORETRY | __GFP_NOWARN | __GFP_COMP,
-				order);
-			if (likely(pages != NULL))
-				goto have_pages;
-			order--;
-		}
-
-		pages = mempool_alloc(&cc->page_pool, gfp_mask);
-		if (!pages) {
+	for (i = 0; i < nr_iovecs; i++) {
+		page = mempool_alloc(&cc->page_pool, gfp_mask);
+		if (!page) {
 			crypt_free_buffer_pages(cc, clone);
 			bio_put(clone);
 			gfp_mask |= __GFP_DIRECT_RECLAIM;
-			order = 0;
 			goto retry;
 		}
 
-have_pages:
-		size_to_add = min((unsigned)PAGE_SIZE << order, remaining_size);
-		__bio_add_page(clone, pages, size_to_add, 0);
-		remaining_size -= size_to_add;
+		len = (remaining_size > PAGE_SIZE) ? PAGE_SIZE : remaining_size;
+
+		__bio_add_page(clone, page, len, 0);
+		remaining_size -= len;
 	}
 
 	/* Allocate space for integrity tags */
@@ -1738,15 +1720,12 @@ static struct bio *crypt_alloc_buffer(struct dm_crypt_io *io, unsigned int size)
 
 static void crypt_free_buffer_pages(struct crypt_config *cc, struct bio *clone)
 {
-	struct folio_iter fi;
+	struct bio_vec *bv;
+	struct bvec_iter_all iter_all;
 
-	if (clone->bi_vcnt > 0) { /* bio_for_each_folio_all crashes with an empty bio */
-		bio_for_each_folio_all(fi, clone) {
-			if (folio_test_large(fi.folio))
-				folio_put(fi.folio);
-			else
-				mempool_free(&fi.folio->page, &cc->page_pool);
-		}
+	bio_for_each_segment_all(bv, clone, iter_all) {
+		BUG_ON(!bv->bv_page);
+		mempool_free(bv->bv_page, &cc->page_pool);
 	}
 }
 
-- 
2.41.0

